{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Omanshu_Thapliyal_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omanshuthapliyal/ML2Coursework/blob/master/Omanshu_Thapliyal_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKRfNs6ICuLD",
        "colab_type": "text"
      },
      "source": [
        "#Student Name: Omanshu Thapliyal\n",
        "#ECE 595 Machine Learning II\n",
        "#Project 3: GAN - Student Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nfXEi7WC0OA",
        "colab_type": "code",
        "outputId": "0654d411-d249-425f-bcff-2808d925f91d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Import necessary packages\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Input\n",
        "from keras.models import Model,Sequential\n",
        "from keras.datasets import mnist\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import adam\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fACNZwo4DBrP",
        "colab_type": "text"
      },
      "source": [
        "#Part 1: Implementing the GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAKtkDn6DQsy",
        "colab_type": "code",
        "outputId": "7ecdbba5-9c32-4fa3-a7f6-d47c3344eefa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Load MNIST data and normalize to [-1, 1]\n",
        "(data_train, _), (data_test, _) = mnist.load_data()\n",
        "data_train = 2*(data_train/255.0 - 0.5)\n",
        "data_test = 2*(data_test/255.0 - 0.5)\n",
        "print(data_test.min(),data_test.max())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "11501568/11490434 [==============================] - 1s 0us/step\n",
            "(-1.0, 1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmVVm4CnWGPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The D-dimensional noise vector length\n",
        "latent_dim = 100\n",
        "data_dim = 784\n",
        "\n",
        "# Optimizer for discriminator, which will have a higher learning rate than adversarial model\n",
        "def adam_optimizer():\n",
        "    return adam(lr = 0.002, beta_1 = 0.5, beta_2 = 0.999)\n",
        "\n",
        "# Optimizer for generator, which will have a lower learning rate than adversarial model\n",
        "def gan_optimizer():\n",
        "    return adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUQ1aau7cN_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Genrerator model\n",
        "def create_generator():\n",
        "  # Input layer: a 100-dimensional noise vector\n",
        "  generator = Sequential()\n",
        "  generator.add(Dense(100, input_dim = latent_dim))\n",
        "  # First hidden layer: a dense (fully-connected) layer consisting of 200 - 300 units with a LeakyReLU activation\n",
        "  generator.add(Dense(250, activation=LeakyReLU(0.5)) )\n",
        "  # Second hidden layer: a dense (fully-connected) layer consisting of 500 - 600 units with a LeakyReLU activation\n",
        "  generator.add(Dense(550, activation=LeakyReLU(0.5)) )\n",
        "  # Third hidden layer: a dense (fully-connected) layer consisting of 1000 - 1200 units with a LeakyReLU activation\n",
        "  generator.add(Dense(1100, activation=LeakyReLU(0.5)) )\n",
        "  # Output layer: the 784-dimensional generated image with a hyperbolic tangent activation\n",
        "  generator.add(Dense(data_dim, activation = 'tanh'))\n",
        "  # Compiling model\n",
        "  generator.compile(loss = 'mean_squared_error', \n",
        "                    Optimizer = adam_optimizer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6YqtA9McPf6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discriminator model\n",
        "def create_discriminator():\n",
        "  discriminator = Sequential()\n",
        "  # Input layer: a 784-dimensional vector of the image data\n",
        "  discriminator.add(Dense(784))\n",
        "  # First hidden layer: a dense (fully-connected) layer consisting of 1000 - 1200 units with a LeakyReLU activation (add a ‘Dropout’ layer to avoid overfitting)\n",
        "  discriminator.add(Dense(1100, activation=LeakyReLU(0.5)) )\n",
        "  # Second hidden layer: a dense (fully-connected) layer consisting of 500 - 600 units with a LeakyReLU activation (add a ‘Dropout’ layer to avoid overfitting)\n",
        "  discriminator.add(Dense(550, activation=LeakyReLU(0.5)) )\n",
        "  # Third hidden layer: a dense (fully-connected) layer consisting of 200 - 300 units with a LeakyReLU activation\n",
        "  discriminator.add(Dense(250, activation=LeakyReLU(0.5)) )\n",
        "  # Output layer: a single Dense unit with a sigmoid activation indicating whether the image is ‘real’ or ‘fake’\n",
        "  discriminator.add(Dense(units=1, activation = 'sigmoid'))\n",
        "  discriminator.compile(loss='mean_squared_error', \n",
        "                        Optimzer = adam_optimizer(), \n",
        "                        metrics = ['accuracy'])\n",
        "\n",
        "  return discriminator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5m0BorDel6A",
        "colab_type": "code",
        "outputId": "e931c512-1fb0-4c20-de2b-86ad2201f95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TB4Qu4EnM0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GAN model\n",
        "def create_gan(discriminator, generator):\n",
        "  # FILL THIS IN\n",
        "  discriminator.trainable = False\n",
        "  gan_input = Input(shape = (latent_dim,))\n",
        "  x = generator(gan_input)\n",
        "  gan_output = discriminator(x)\n",
        "  gan = Model(inputs = gan_input, Output = gan_output)\n",
        "  gan.compile(loss = 'mean_squared_error', \n",
        "              optimizer = gan_optimizer(), \n",
        "              metrics = ['accuracy'])\n",
        "  return gan\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfl05jSBnM8m",
        "colab_type": "code",
        "outputId": "2c12dbc2-3971-434e-edb1-875783c83e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "# Creating Graph for GAN\n",
        "generator = create_generator()\n",
        "discriminator = create_discriminator()\n",
        "gan = create_gan(discriminator, generator)\n",
        "\n",
        "# Model and training parameters\n",
        "epochs = 5 #10000\n",
        "batch_size = 50\n",
        "sample_interval = 5 #10000\n",
        "\n",
        "# Array to save training history\n",
        "training_meta_data = np.zeros([epochs, 4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c2216e3f09e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Model and training parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-5347e72798de>\u001b[0m in \u001b[0;36mcreate_generator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# Compiling model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   generator.compile(loss = 'mean_squared_error', \n\u001b[0;32m---> 15\u001b[0;31m                     Optimizer = adam_optimizer())\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: compile() takes at least 2 arguments (2 given)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4hLQhOBnXYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the GAN\n",
        "for e in range(1, epochs+1):\n",
        "    # Generate random noise as input\n",
        "    N = batch_size*latent_dim\n",
        "    rand_input = np.random.multivariate_normal(mean = np.zeros(N, 1),\n",
        "                                               cov = np.eye(N,N))\n",
        "    rand_input = rand_input.reshape((batch_size, latent_dim))\n",
        "    # Generate fake MNIST images from generated noise\n",
        "    fake_images = generator(rand_input)\n",
        "    # Get a random set of real MNIST images\n",
        "    real_images = np.random.choice(data_train, size = batch_size)\n",
        "    # Concatenate real and fake images into a single array (or batch)\n",
        "    data_total = np.concatenate((real_images, fake_images))\n",
        "    # Assign training labels (assign high probability, but not 1, to real images)\n",
        "    labels_real = np.ones(real_images.shape[0])\n",
        "    labels_fake = np.ones(fake_images.shape[0])\n",
        "    labels_discriminator = np.concatenate(labels_real, labels_fake)\n",
        "\n",
        "    # Allow discriminator parameters to be updated\n",
        "    discriminator.trainable = True\n",
        "    # Train discriminator on batch of real and fake images. Assign loss and accuracy to variable\n",
        "    discriminator.train(data_total, labels_discriminator)\n",
        "\n",
        "    # Train adversarial model and try to fool discriminator (with incorrect label) \n",
        "    # by generating a new batch of noise and assign them labels of real data\n",
        "    \n",
        "\n",
        "    # Keep discriminator weights constant while training generator\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    # Train GAN (without updating discriminator weights) on new batch of fake images. Assign loss and accuracy to variable\n",
        "    generator.train(data_total, labels_discriminator)\n",
        "\n",
        "    # Save training status\n",
        "    # Discriminator and model loss\n",
        "    training_meta_data[e-1, 0] = d_loss[0]\n",
        "    training_meta_data[e-1, 1] = gan_loss[0]\n",
        "\n",
        "    # Discriminator and model accuracy\n",
        "    training_meta_data[e-1, 2] = d_loss[1]\n",
        "    training_meta_data[e-1, 3] = gan_loss[1]\n",
        "\n",
        "\n",
        "    # If at sample interval, print training status and save samples\n",
        "    if e % sample_interval == 0:\n",
        "      \n",
        "        # Print training status\n",
        "        print(\"Epoch %d\" %e)\n",
        "        log_mesg = \"%d: [Discriminaotr loss: %f, acc: %f]\" % (e, d_loss[0], d_loss[1])\n",
        "        log_mesg = \"%s  [GAN loss: %f, acc: %f]\" % (log_mesg, gan_loss[0], gan_loss[1])\n",
        "        print(log_mesg)\n",
        "        \n",
        "        # Plot images \n",
        "        r, c = 5, 5\n",
        "\n",
        "        # Create images from the noise (predict the outcome of the noise)\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow((gen_imgs[cnt].reshape(28, 28)), cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqRJEDeIG9mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot model loss vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUJwhntuHJK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot accuracy vs epoch\n",
        "#FILL THIS CODE BLOCK IN AND PRODUCE PLOT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC_kPLFKHS7c",
        "colab_type": "text"
      },
      "source": [
        "Answer the following questions:\n",
        "\n",
        "\n",
        "\n",
        "1.   Why does the accuracy of the discriminator remain around 50%? Is this a good trait of the GAN? \n",
        "\n",
        "  ANS: \n",
        "\n",
        "\n",
        "2.   How could this model be modified to produce cleaner (less noisy) images? \n",
        "\n",
        "  ANS: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZBFSk1RHX5J",
        "colab_type": "text"
      },
      "source": [
        "#Part 2: Generating samples using trained generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHaVnENuHcKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate ten images from Gaussian noise using the trained generator from Part 1\n",
        "# FILL THIS IN\n",
        "\n",
        "# Re-scale generated images to lie in [0, 1]\n",
        "# FILL THIS IN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nak-dm-CIC6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize generated noise\n",
        "r, c = 2, 5\n",
        "fig, axs = plt.subplots(r, c)\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "    for j in range(c):\n",
        "        axs[i,j].imshow((noise[cnt].reshape(10, 10)), cmap='gray')\n",
        "        axs[i,j].axis('off')\n",
        "        cnt += 1\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-Jir5ULIITP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize generated samples\n",
        "r, c = 2, 5\n",
        "fig, axs = plt.subplots(r, c)\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "    for j in range(c):\n",
        "        axs[i,j].imshow((generated_images[cnt].reshape(28, 28)), cmap='gray')\n",
        "        axs[i,j].axis('off')\n",
        "        cnt += 1\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4I4Q8fhIheQ",
        "colab_type": "text"
      },
      "source": [
        "#Part 3: Testing accuracy of generated images on ten samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHjnlh6dIiMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load mnist classifier and generated images\n",
        "mnist_classifier = load_model('mnist_classifier.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_BFS0cgInWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ASSIGN CLASSES\n",
        "labels = []\n",
        "\n",
        "# Convert integer labels to one-hot labels \n",
        "labels = keras.utils.np_utils.to_categorical(labels, num_classes=10)\n",
        "\n",
        "# Show classifications\n",
        "# FILL THIS IN \n",
        "\n",
        "# Evaluate accuracy\n",
        "# FILL THIS IN "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxCLMvJnI95c",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}